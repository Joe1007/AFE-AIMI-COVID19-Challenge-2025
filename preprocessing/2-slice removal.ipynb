{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "\n",
    "\n",
    "import timm\n",
    "from timm.models.efficientnet import *\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "\n",
    "import glob\n",
    "\n",
    "import pickle, pandas as pd, numpy as np, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ct_all_pd = pd.read_csv('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/chih_4_fold_covid_train_df.csv')[['path','slice_name']]\n",
    "train_ct_all_pd['full_path'] = train_ct_all_pd['path']+'/'+train_ct_all_pd['slice_name']\n",
    "train_ct_all_list = train_ct_all_pd.full_path.values.tolist()\n",
    "valid_ct_all_pd = pd.read_csv('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/chih_4_fold_covid_valid_df.csv')[['path','slice_name']]\n",
    "valid_ct_all_pd['full_path'] = valid_ct_all_pd['path']+'/'+valid_ct_all_pd['slice_name']\n",
    "valid_ct_all_list = valid_ct_all_pd.full_path.values.tolist()\n",
    "print(train_ct_all_pd.shape, valid_ct_all_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_area=[]\n",
    "for path in tqdm(train_ct_all_list):\n",
    "    img = cv2.imread(path)\n",
    "    img2=ndimage.minimum_filter(img,5)\n",
    "    img_b=np.where(img2<100,0,255)\n",
    "    mask=scipy.ndimage.binary_fill_holes(img_b[:,:,0])\n",
    "    mask_=mask*255\n",
    "    aaa=mask_-img_b[:,:,0]\n",
    "    train_area.append(aaa.sum()/255)\n",
    "\n",
    "modified_list = [item.replace('train','train_pure_crop_challenge') for item in train_ct_all_list]\n",
    "train_area_df=pd.DataFrame((zip(modified_list, train_area)), columns = ['path', 'area'])\n",
    "train_area_df.to_csv(\"/ssd7/ICCV2025_COVID19/processing_by_hospital_0/train_area_df1_challenge.csv\", index=False, encoding='utf-8-sig')\n",
    "train_area_df\n",
    "print(train_area_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_area=[]\n",
    "for path in tqdm(valid_ct_all_list):\n",
    "    img = cv2.imread(path)\n",
    "    img2=ndimage.minimum_filter(img,5)\n",
    "    img_b=np.where(img2<100,0,255)\n",
    "    mask=scipy.ndimage.binary_fill_holes(img_b[:,:,0])\n",
    "    mask_=mask*255\n",
    "    aaa=mask_-img_b[:,:,0]\n",
    "    valid_area.append(aaa.sum()/255)\n",
    "\n",
    "modified_list = [item.replace('val','valid_pure_crop_challenge') for item in valid_ct_all_list]\n",
    "valid_area_df=pd.DataFrame((zip(modified_list, valid_area)), columns = ['path', 'area'])\n",
    "valid_area_df.to_csv(\"/ssd7/ICCV2025_COVID19/processing_by_hospital_0/valid_area_df1_challenge.csv\", index=False, encoding='utf-8-sig')ㄣ\n",
    "valid_area_df\n",
    "print(valid_area_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_area_df=pd.read_csv(\"/ssd7/ICCV2025_COVID19/processing_by_hospital_0/train_area_df1_challenge.csv\")\n",
    "valid_area_df=pd.read_csv(\"/ssd7/ICCV2025_COVID19/processing_by_hospital_0/valid_area_df1_challenge.csv\")\n",
    "print(train_area_df.shape, valid_area_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_area_df[\"ct_path\"]=train_area_df[\"path\"].apply(lambda x: \"/\".join(x.split(\"/\")[:-1]))\n",
    "valid_area_df[\"ct_path\"]=valid_area_df[\"path\"].apply(lambda x: \"/\".join(x.split(\"/\")[:-1]))\n",
    "\n",
    "train_area_df[\"ct_slice\"]=train_area_df[\"path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "valid_area_df[\"ct_slice\"]=valid_area_df[\"path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "\n",
    "train_area_df.sort_values(by=['ct_path', 'ct_slice'], inplace=True)\n",
    "valid_area_df.sort_values(by=['ct_path', 'ct_slice'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_max(a,w=0.4):\n",
    "    l=len(a)\n",
    "    k=int(np.ceil(l*w))\n",
    "    d=0\n",
    "    tmp_max=0\n",
    "    # print(l, k)\n",
    "    for i in range(l-k+1):\n",
    "        if np.sum(a[i:i+k])>tmp_max:\n",
    "            tmp_max=np.sum(a[i:i+k])\n",
    "            d=i\n",
    "    return d,d+k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_path_list=train_area_df[\"ct_path\"].unique()\n",
    "train_dic={}\n",
    "for i in tqdm(range(len(ct_path_list))):\n",
    "    tmp_df=train_area_df[train_area_df[\"ct_path\"]==ct_path_list[i]].reset_index(drop=True)\n",
    "    train_dic[ct_path_list[i]]=list(sum_max(tmp_df[\"area\"].values,0.5))\n",
    "\n",
    "ct_path_list=valid_area_df[\"ct_path\"].unique()\n",
    "valid_dic={}\n",
    "for i in tqdm(range(len(ct_path_list))):\n",
    "    tmp_df=valid_area_df[valid_area_df[\"ct_path\"]==ct_path_list[i]].reset_index(drop=True)\n",
    "    valid_dic[ct_path_list[i]]=list(sum_max(tmp_df[\"area\"].values,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/train_dic1_05_challenge.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/valid_dic1_05_challenge.pickle', 'wb') as handle:\n",
    "    pickle.dump(valid_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/train_dic1_05_challenge.pickle', 'rb') as f:\n",
    "    train_dic = pickle.load(f)\n",
    "with open('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/valid_dic1_05_challenge.pickle', 'rb') as f:\n",
    "    valid_dic = pickle.load(f)\n",
    "print(len(train_dic),len(valid_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(None, columns=['path', 'filename', 'label'])\n",
    "valid_df = pd.DataFrame(None, columns=['path', 'filename', 'label'])\n",
    "\n",
    "print(\"=\"*10, \"loading data DataFrame\", \"=\"*10)\n",
    "\n",
    "# 處理訓練資料\n",
    "for path in list(train_dic.keys()):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"⚠️  跳過不存在的路徑: {path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        image_list = os.listdir(path)\n",
    "        if len(image_list) == 0:\n",
    "            print(f\"⚠️  跳過空資料夾: {path}\")\n",
    "            continue\n",
    "            \n",
    "        image_list.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        temp_df = pd.DataFrame([path]*len(image_list), columns=['path'])\n",
    "        temp_df['filename'] = image_list\n",
    "        if 'non-covid' in temp_df.path[0]:\n",
    "            temp_df['label'] = [0]*len(image_list)\n",
    "        else:\n",
    "            temp_df['label'] = [1]*len(image_list)\n",
    "        train_df = pd.concat([train_df, temp_df])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 處理路徑時發生錯誤: {path}, 錯誤: {e}\")\n",
    "        continue\n",
    "\n",
    "# 處理驗證資料\n",
    "for path in list(valid_dic.keys()):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"⚠️  跳過不存在的路徑: {path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        image_list = os.listdir(path)\n",
    "        if len(image_list) == 0:\n",
    "            print(f\"⚠️  跳過空資料夾: {path}\")\n",
    "            continue\n",
    "            \n",
    "        image_list.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        temp_df = pd.DataFrame([path]*len(image_list), columns=['path'])\n",
    "        temp_df['filename'] = image_list\n",
    "        if 'non-covid' in temp_df.path[0]:\n",
    "            temp_df['label'] = [0]*len(image_list)\n",
    "        else:\n",
    "            temp_df['label'] = [1]*len(image_list)\n",
    "        valid_df = pd.concat([valid_df, temp_df])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 處理路徑時發生錯誤: {path}, 錯誤: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"✅ 完成！訓練資料: {train_df.shape[0]} 筆, 驗證資料: {valid_df.shape[0]} 筆\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "cp_train_dic = copy.deepcopy(train_dic)\n",
    "cp_valid_dic = copy.deepcopy(valid_dic)\n",
    "print(len(train_dic), len(valid_dic))\n",
    "print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_count_t = 0\n",
    "filter_num = 5\n",
    "\n",
    "# 處理訓練資料\n",
    "for path_ in train_dic:\n",
    "    if not os.path.exists(path_):\n",
    "        print(f\"⚠️  跳過不存在的路徑: {path_}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        i = len(os.listdir(path_))\n",
    "        if i < filter_num:\n",
    "            print(f\"張數{i}\", path_)\n",
    "            drop_count_t = drop_count_t + i\n",
    "            if path_ in cp_train_dic:\n",
    "                del cp_train_dic[path_]\n",
    "            train_df = train_df[train_df.path != path_]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 處理路徑時發生錯誤: {path_}, 錯誤: {e}\")\n",
    "        continue\n",
    "\n",
    "drop_count_v = 0\n",
    "\n",
    "# 處理驗證資料\n",
    "for path_ in valid_dic:\n",
    "    if not os.path.exists(path_):\n",
    "        print(f\"⚠️  跳過不存在的路徑: {path_}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        i = len(os.listdir(path_))\n",
    "        if i < filter_num:\n",
    "            print(f\"張數{i}\", path_)\n",
    "            drop_count_v = drop_count_v + i\n",
    "            if path_ in cp_valid_dic:\n",
    "                del cp_valid_dic[path_]\n",
    "            valid_df = valid_df[valid_df.path != path_]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 處理路徑時發生錯誤: {path_}, 錯誤: {e}\")\n",
    "        continue\n",
    "\n",
    "print(len(cp_train_dic), len(cp_valid_dic))\n",
    "print(train_df.shape, valid_df.shape)\n",
    "print(drop_count_t, drop_count_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['path', 'label']]\n",
    "valid_df = valid_df[['path', 'label']]\n",
    "train_df = train_df.drop_duplicates(subset='path')\n",
    "valid_df = valid_df.drop_duplicates(subset='path')\n",
    "print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/filter_slice_train_dic1_05_challenge.pickle', 'wb') as handle:\n",
    "    pickle.dump(cp_train_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('/ssd7/ICCV2025_COVID19/processing_by_hospital_0/filter_slice_valid_dic1_05_challenge.pickle', 'wb') as handle:\n",
    "    pickle.dump(cp_valid_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "train_df.to_csv(\"/ssd7/ICCV2025_COVID19/processing_by_hospital_0/filter_slice_train_df_challenge.csv\", index=False, encoding='utf-8-sig')\n",
    "valid_df.to_csv(\"/ssd7/ICCV2025_COVID19/processing_by_hospital_0/filter_slice_valid_df_challenge.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
