{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train è³‡æ–™é›†è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ============================================================================\n",
    "# å®Œæ•´è³‡æ–™å‰è™•ç†ï¼šå‰µå»ºä¹¾æ·¨çš„ track1_fixed è³‡æ–™å¤¾\n",
    "# è™•ç†å®Œæ•´çš„è³‡æ–™çµæ§‹ï¼štrain/val -> covid/non-covid -> ct_scan_i -> *.jpg\n",
    "# ============================================================================\n",
    "\n",
    "è³‡æ–™çµæ§‹:\n",
    "track1/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ annotations/          # CSV æª”æ¡ˆï¼Œç›´æ¥è¤‡è£½\n",
    "â”‚   â”œâ”€â”€ covid/\n",
    "â”‚   â”‚   â”œâ”€â”€ ct_scan_0/        # åŒ…å« *.jpg\n",
    "â”‚   â”‚   â”œâ”€â”€ ct_scan_1/\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ non-covid/\n",
    "â”‚       â”œâ”€â”€ ct_scan_0/\n",
    "â”‚       â”œâ”€â”€ ct_scan_1/\n",
    "â”‚       â””â”€â”€ ...\n",
    "â””â”€â”€ val/\n",
    "    â”œâ”€â”€ annotations/          # CSV æª”æ¡ˆï¼Œç›´æ¥è¤‡è£½\n",
    "    â”œâ”€â”€ covid/\n",
    "    â”‚   â”œâ”€â”€ ct_scan_0/\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â””â”€â”€ non-covid/\n",
    "        â”œâ”€â”€ ct_scan_0/\n",
    "        â””â”€â”€ ...\n",
    "\n",
    "Args:\n",
    "    source_path: åŸå§‹ track1 è·¯å¾‘\n",
    "    target_path: ç›®æ¨™ track1_fixed è·¯å¾‘\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def create_clean_dataset_complete(source_path, target_path):\n",
    "\n",
    "    source_path = Path(source_path)\n",
    "    target_path = Path(target_path)\n",
    "    \n",
    "    print(f\"é–‹å§‹è™•ç†å®Œæ•´è³‡æ–™é›†...\")\n",
    "    print(f\"ä¾†æºè·¯å¾‘: {source_path}\")\n",
    "    print(f\"ç›®æ¨™è·¯å¾‘: {target_path}\")\n",
    "    \n",
    "    # å‰µå»ºæ ¹ç›®éŒ„\n",
    "    target_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    total_copied = 0\n",
    "    total_skipped = 0\n",
    "    total_csv_copied = 0\n",
    "    \n",
    "    # è™•ç† train å’Œ val è³‡æ–™å¤¾\n",
    "    for split in ['train', 'val']:\n",
    "        source_split_path = source_path / split\n",
    "        target_split_path = target_path / split\n",
    "        \n",
    "        if not source_split_path.exists():\n",
    "            print(f\"è­¦å‘Š: {source_split_path} ä¸å­˜åœ¨ï¼Œè·³é\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"è™•ç† {split.upper()} è³‡æ–™å¤¾\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # å‰µå»º split è³‡æ–™å¤¾\n",
    "        target_split_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        # 1. è™•ç† annotations è³‡æ–™å¤¾ï¼ˆç›´æ¥è¤‡è£½ CSV æª”æ¡ˆï¼‰\n",
    "        source_annotations = source_split_path / 'annotations'\n",
    "        if source_annotations.exists():\n",
    "            target_annotations = target_split_path / 'annotations'\n",
    "            if target_annotations.exists():\n",
    "                shutil.rmtree(target_annotations)  # å…ˆæ¸…ç©ºç›®æ¨™è³‡æ–™å¤¾\n",
    "            shutil.copytree(source_annotations, target_annotations)\n",
    "            \n",
    "            csv_files = list(target_annotations.glob('*.csv'))\n",
    "            total_csv_copied += len(csv_files)\n",
    "            print(f\"âœ… è¤‡è£½ annotations: {len(csv_files)} å€‹ CSV æª”æ¡ˆ\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  {split}/annotations ä¸å­˜åœ¨\")\n",
    "        \n",
    "        # 2. å‰µå»º covid å’Œ non-covid è³‡æ–™å¤¾\n",
    "        target_split_path.joinpath('covid').mkdir(exist_ok=True)\n",
    "        target_split_path.joinpath('non-covid').mkdir(exist_ok=True)\n",
    "        \n",
    "        # 3. è™•ç† covid å’Œ non-covid è³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡\n",
    "        for category in ['covid', 'non-covid']:\n",
    "            source_category_path = source_split_path / category\n",
    "            target_category_path = target_split_path / category\n",
    "            \n",
    "            if not source_category_path.exists():\n",
    "                print(f\"âš ï¸  {split}/{category} ä¸å­˜åœ¨ï¼Œè·³é\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n--- è™•ç† {split}/{category} ---\")\n",
    "            \n",
    "            split_copied = 0\n",
    "            split_skipped = 0\n",
    "            ct_folder_count = 0\n",
    "            \n",
    "            # éæ­·æ‰€æœ‰ ct_scan_i è³‡æ–™å¤¾\n",
    "            ct_folders = sorted([d for d in source_category_path.iterdir() \n",
    "                               if d.is_dir() and d.name.startswith('ct_scan_')])\n",
    "            \n",
    "            for ct_folder in ct_folders:\n",
    "                target_ct_folder = target_category_path / ct_folder.name\n",
    "                target_ct_folder.mkdir(exist_ok=True)\n",
    "                \n",
    "                copied_in_folder = 0\n",
    "                skipped_in_folder = 0\n",
    "                \n",
    "                # è™•ç†è©² ct_scan è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰ jpg æª”æ¡ˆ\n",
    "                jpg_files = list(ct_folder.glob('*.jpg'))\n",
    "                \n",
    "                for jpg_file in jpg_files:\n",
    "                    # è·³é macOS ç³»çµ±æª”æ¡ˆ\n",
    "                    if jpg_file.name.startswith('._'):\n",
    "                        skipped_in_folder += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # æª¢æŸ¥æª”æ¡ˆå¤§å°ï¼ˆç³»çµ±æª”æ¡ˆé€šå¸¸å¾ˆå°ï¼‰\n",
    "                    file_size = jpg_file.stat().st_size\n",
    "                    if file_size < 10000:  # å°æ–¼ 10KB çš„æª”æ¡ˆå¯èƒ½æœ‰å•é¡Œ\n",
    "                        print(f\"    è·³éå°æª”æ¡ˆ: {ct_folder.name}/{jpg_file.name} ({file_size} bytes)\")\n",
    "                        skipped_in_folder += 1\n",
    "                        continue\n",
    "                    \n",
    "                    # è¤‡è£½æ­£å¸¸æª”æ¡ˆ\n",
    "                    target_file = target_ct_folder / jpg_file.name\n",
    "                    shutil.copy2(jpg_file, target_file)\n",
    "                    copied_in_folder += 1\n",
    "                \n",
    "                split_copied += copied_in_folder\n",
    "                split_skipped += skipped_in_folder\n",
    "                \n",
    "                if copied_in_folder > 0:\n",
    "                    ct_folder_count += 1\n",
    "                    print(f\"  âœ… {ct_folder.name}: {copied_in_folder} å€‹æª”æ¡ˆ \"\n",
    "                          f\"(è·³é {skipped_in_folder} å€‹)\")\n",
    "                else:\n",
    "                    print(f\"  âš ï¸  {ct_folder.name}: æ²’æœ‰æœ‰æ•ˆæª”æ¡ˆ\")\n",
    "            \n",
    "            total_copied += split_copied\n",
    "            total_skipped += split_skipped\n",
    "            \n",
    "            print(f\"--- {split}/{category} ç¸½çµ ---\")\n",
    "            print(f\"  CT è³‡æ–™å¤¾æ•¸: {ct_folder_count}\")\n",
    "            print(f\"  æœ‰æ•ˆåœ–ç‰‡: {split_copied} å€‹\")\n",
    "            print(f\"  è·³éæª”æ¡ˆ: {split_skipped} å€‹\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"è™•ç†å®Œæˆ!\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"ç¸½å…±è¤‡è£½åœ–ç‰‡: {total_copied} å€‹\")\n",
    "    print(f\"ç¸½å…±è·³éæª”æ¡ˆ: {total_skipped} å€‹\")\n",
    "    print(f\"ç¸½å…±è¤‡è£½ CSV: {total_csv_copied} å€‹\")\n",
    "    \n",
    "    return total_copied, total_skipped, total_csv_copied\n",
    "\n",
    "# é©—è­‰æ¸…ç†å¾Œçš„è³‡æ–™é›†çµæ§‹å’Œå…§å®¹\n",
    "def verify_clean_dataset(dataset_path):\n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"é©—è­‰è³‡æ–™é›†: {dataset_path}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        split_path = dataset_path / split\n",
    "        if not split_path.exists():\n",
    "            print(f\"âš ï¸  {split} è³‡æ–™å¤¾ä¸å­˜åœ¨\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- {split.upper()} ---\")\n",
    "        \n",
    "        # æª¢æŸ¥ annotations\n",
    "        annotations_path = split_path / 'annotations'\n",
    "        if annotations_path.exists():\n",
    "            csv_files = list(annotations_path.glob('*.csv'))\n",
    "            print(f\"  ğŸ“„ annotations: {len(csv_files)} å€‹ CSV æª”æ¡ˆ\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸  annotations ä¸å­˜åœ¨\")\n",
    "        \n",
    "        # æª¢æŸ¥ covid å’Œ non-covid\n",
    "        for category in ['covid', 'non-covid']:\n",
    "            category_path = split_path / category\n",
    "            if category_path.exists():\n",
    "                ct_folders = [d for d in category_path.iterdir() if d.is_dir()]\n",
    "                total_images = sum(len(list(folder.glob('*.jpg'))) \n",
    "                                 for folder in ct_folders)\n",
    "                print(f\"  ğŸ¥ {category}: {len(ct_folders)} å€‹ CT è³‡æ–™å¤¾, \"\n",
    "                      f\"{total_images} å¼µåœ–ç‰‡\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸  {category} ä¸å­˜åœ¨\")\n",
    "\n",
    "# ============================================================================\n",
    "# åŸ·è¡Œè³‡æ–™å‰è™•ç†\n",
    "# ============================================================================\n",
    "\n",
    "# è¨­å®šè·¯å¾‘\n",
    "source_data_path = '/ssd7/ICCV2025_COVID19/track1'\n",
    "target_data_path = '/ssd7/ICCV2025_COVID19/track1_fixed'\n",
    "\n",
    "print(\"é–‹å§‹å‰µå»ºä¹¾æ·¨çš„è³‡æ–™é›†...\")\n",
    "\n",
    "# å‰µå»ºä¹¾æ·¨çš„è³‡æ–™é›†\n",
    "try:\n",
    "    copied_files, skipped_files, csv_files = create_clean_dataset_complete(\n",
    "        source_data_path, target_data_path)\n",
    "    \n",
    "    # é©—è­‰çµæœ\n",
    "    verify_clean_dataset(target_data_path)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æˆåŠŸ! ä¹¾æ·¨çš„è³‡æ–™é›†å·²å‰µå»ºåœ¨: {target_data_path}\")\n",
    "    print(\"ç¾åœ¨å¯ä»¥ä½¿ç”¨ track1_fixed è·¯å¾‘é€²è¡Œå¾ŒçºŒè™•ç†ï¼\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4é†«é™¢åˆ†é–‹è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reorganize_by_hospital(source_dir, target_dir):\n",
    "    \"\"\"\n",
    "    æ ¹æ“šCSVä¸­çš„é†«å­¸ä¸­å¿ƒæ¨™è¨˜é‡æ–°çµ„ç¹”è³‡æ–™é›†\n",
    "    \n",
    "    Args:\n",
    "        source_dir: åŸå§‹è³‡æ–™ç›®éŒ„ (track1_fixed)\n",
    "        target_dir: ç›®æ¨™è³‡æ–™ç›®éŒ„ (æ–°çš„çµ„ç¹”çµæ§‹)\n",
    "    \"\"\"\n",
    "    \n",
    "    # å®šç¾©è·¯å¾‘\n",
    "    source_path = Path(source_dir)\n",
    "    target_path = Path(target_dir)\n",
    "    \n",
    "    # å‰µå»ºç›®æ¨™æ ¹ç›®éŒ„\n",
    "    target_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # è™•ç†trainå’Œvalå…©å€‹éƒ¨åˆ†\n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\n=== è™•ç† {split} è³‡æ–™ ===\")\n",
    "        \n",
    "        # è™•ç†COVIDå’ŒNon-COVIDå…©å€‹é¡åˆ¥\n",
    "        for category in ['covid', 'non-covid']:\n",
    "            print(f\"è™•ç† {split}/{category}...\")\n",
    "            \n",
    "            # è®€å–å°æ‡‰çš„CSVæª”æ¡ˆ\n",
    "            csv_file = source_path / split / 'annotations' / f'{split}_{category.replace(\"-\", \"_\")}.csv'\n",
    "            \n",
    "            if not csv_file.exists():\n",
    "                print(f\"è­¦å‘Š: CSVæª”æ¡ˆä¸å­˜åœ¨ - {csv_file}\")\n",
    "                continue\n",
    "                \n",
    "            # è®€å–CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"è®€å–åˆ° {len(df)} ç­†è³‡æ–™\")\n",
    "            \n",
    "            # ç²å–æ‰€æœ‰é†«å­¸ä¸­å¿ƒ\n",
    "            hospitals = df['data_centre'].unique()\n",
    "            print(f\"ç™¼ç¾é†«å­¸ä¸­å¿ƒ: {hospitals}\")\n",
    "            \n",
    "            # ç‚ºæ¯å€‹é†«å­¸ä¸­å¿ƒå‰µå»ºç›®éŒ„çµæ§‹\n",
    "            for hospital in hospitals:\n",
    "                hospital_dir = target_path / f'hospital_{hospital}'\n",
    "                hospital_split_dir = hospital_dir / split / category\n",
    "                hospital_split_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # æ ¹æ“šCSVè¤‡è£½æª”æ¡ˆ\n",
    "            hospital_data = df.groupby('data_centre')\n",
    "            \n",
    "            for hospital_id, group in hospital_data:\n",
    "                print(f\"  è™•ç†é†«å­¸ä¸­å¿ƒ {hospital_id}: {len(group)} å€‹CTæƒæ\")\n",
    "                \n",
    "                target_hospital_dir = target_path / f'hospital_{hospital_id}' / split / category\n",
    "                \n",
    "                for _, row in tqdm(group.iterrows(), desc=f\"Hospital {hospital_id}\", leave=False):\n",
    "                    ct_scan_name = row['ct_scan_name']\n",
    "                    \n",
    "                    # ä¾†æºCTæƒæè³‡æ–™å¤¾\n",
    "                    source_ct_dir = source_path / split / category / ct_scan_name\n",
    "                    \n",
    "                    # ç›®æ¨™CTæƒæè³‡æ–™å¤¾\n",
    "                    target_ct_dir = target_hospital_dir / ct_scan_name\n",
    "                    \n",
    "                    if source_ct_dir.exists():\n",
    "                        if not target_ct_dir.exists():\n",
    "                            # è¤‡è£½æ•´å€‹CTæƒæè³‡æ–™å¤¾\n",
    "                            shutil.copytree(source_ct_dir, target_ct_dir)\n",
    "                        else:\n",
    "                            print(f\"    è·³éå·²å­˜åœ¨çš„è³‡æ–™å¤¾: {target_ct_dir}\")\n",
    "                    else:\n",
    "                        print(f\"    è­¦å‘Š: ä¾†æºè³‡æ–™å¤¾ä¸å­˜åœ¨ - {source_ct_dir}\")\n",
    "    \n",
    "    print(f\"\\n=== é‡æ–°çµ„ç¹”å®Œæˆ ===\")\n",
    "    print(f\"æ–°çš„è³‡æ–™çµæ§‹ä¿å­˜åœ¨: {target_path}\")\n",
    "    \n",
    "    # é¡¯ç¤ºæœ€çµ‚çµæ§‹\n",
    "    print(\"\\næœ€çµ‚ç›®éŒ„çµæ§‹:\")\n",
    "    show_directory_structure(target_path)\n",
    "\n",
    "def show_directory_structure(path, level=0, max_level=3):\n",
    "    \"\"\"é¡¯ç¤ºç›®éŒ„çµæ§‹\"\"\"\n",
    "    if level > max_level:\n",
    "        return\n",
    "        \n",
    "    items = list(Path(path).iterdir())\n",
    "    items.sort()\n",
    "    \n",
    "    for item in items[:10]:  # é™åˆ¶é¡¯ç¤ºæ•¸é‡\n",
    "        indent = \"  \" * level\n",
    "        if item.is_dir():\n",
    "            print(f\"{indent}{item.name}/\")\n",
    "            if level < max_level:\n",
    "                show_directory_structure(item, level + 1, max_level)\n",
    "        else:\n",
    "            print(f\"{indent}{item.name}\")\n",
    "    \n",
    "    if len(items) > 10:\n",
    "        print(f\"{'  ' * level}... (é‚„æœ‰ {len(items) - 10} å€‹é …ç›®)\")\n",
    "\n",
    "def verify_reorganization(target_dir):\n",
    "    \"\"\"é©—è­‰é‡æ–°çµ„ç¹”çš„çµæœ\"\"\"\n",
    "    target_path = Path(target_dir)\n",
    "    \n",
    "    print(\"\\n=== é©—è­‰é‡æ–°çµ„ç¹”çµæœ ===\")\n",
    "    \n",
    "    hospitals = [d for d in target_path.iterdir() if d.is_dir() and d.name.startswith('hospital_')]\n",
    "    \n",
    "    for hospital_dir in hospitals:\n",
    "        print(f\"\\n{hospital_dir.name}:\")\n",
    "        \n",
    "        for split in ['train', 'val']:\n",
    "            for category in ['covid', 'non-covid']:\n",
    "                category_dir = hospital_dir / split / category\n",
    "                if category_dir.exists():\n",
    "                    ct_scans = [d for d in category_dir.iterdir() if d.is_dir()]\n",
    "                    print(f\"  {split}/{category}: {len(ct_scans)} CTæƒæ\")\n",
    "                else:\n",
    "                    print(f\"  {split}/{category}: ç›®éŒ„ä¸å­˜åœ¨\")\n",
    "\n",
    "# ä½¿ç”¨ç¯„ä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    # è¨­å®šè·¯å¾‘\n",
    "    source_directory = \"/ssd7/ICCV2025_COVID19/track1_fixed\"  # åŸå§‹è³‡æ–™ç›®éŒ„\n",
    "    target_directory = \"/ssd7/ICCV2025_COVID19/track1_by_hospital\"  # æ–°çš„çµ„ç¹”çµæ§‹ç›®éŒ„\n",
    "    \n",
    "    # åŸ·è¡Œé‡æ–°çµ„ç¹”\n",
    "    reorganize_by_hospital(source_directory, target_directory)\n",
    "    \n",
    "    # é©—è­‰çµæœ\n",
    "    verify_reorganization(target_directory)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
